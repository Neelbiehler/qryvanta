---
title: Self Hosting
description: Deployment expectations for running Qryvanta on your own infrastructure.
---

Qryvanta is in active development and is not ready for production use yet.

Use this guidance for local, staging, and controlled internal environments.

## Runtime Stack

- API service
- Web app
- Docs app
- Postgres database
- Background worker process (`qryvanta-worker`) when workflow execution is queued
- Optional Redis service for shared rate limiting and queue-stats cache

## Deployment Direction

1. Docker Compose baseline for local and small deployments.
2. Environment-variable configuration for all services.
3. Database migrations executed during API startup.
4. Explicit backup and restore runbooks before broad rollout.

## Baseline Checklist

- TLS termination configured
- Secrets managed outside source control
- Database backups scheduled and tested
- Health endpoints monitored
- Log and metric collection enabled
- Worker runtime enabled when `WORKFLOW_EXECUTION_MODE=queued`
- Redis enabled when using `SESSION_STORE=redis`, `RATE_LIMIT_STORE=redis`, or `WORKFLOW_QUEUE_STATS_CACHE_BACKEND=redis`

## Worker Runtime Startup

When `WORKFLOW_EXECUTION_MODE=queued`, run at least one worker process:

```bash
cargo run -p qryvanta-worker
```

Scale horizontally by increasing worker replicas; each worker claims leased jobs with `x-qryvanta-worker-id` identity. For deterministic tenant slices, assign `WORKER_PARTITION_COUNT` + `WORKER_PARTITION_INDEX` per worker group, tune per-process throughput with `WORKER_MAX_CONCURRENCY`, and optionally enforce distributed lease ownership with `WORKER_COORDINATION_BACKEND=redis`.

For environment variables and health guidance, see `Configuration`, `Email Delivery`, and `Observability` in this section.
